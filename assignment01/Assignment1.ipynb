{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as matplot\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = pd.read_csv('../data/CONcreTEXT_trial_EN.tsv', sep='\\t') # load data files\n",
    "it_df = pd.read_csv('../data/CONcreTEXT_trial_IT.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "en_df['TOKENS'] = en_df['TEXT'].apply(tokenizer.tokenize).apply(lambda words: ' '.join(words)).apply(lambda x: x.lower())\n",
    "it_df['TOKENS'] = it_df['TEXT'].apply(tokenizer.tokenize).apply(lambda words: ' '.join(words)).apply(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     bring up academic achievements awards and othe...\n",
       "1     please list people you have helped your person...\n",
       "2           add activated carbon straight to your vodka\n",
       "3     place sensors around your garden and when a ca...\n",
       "4     look for a partner that shares your level of a...\n",
       "                            ...                        \n",
       "95       rinse your face with warm water and pat it dry\n",
       "96    staying mentally strong means winning half the...\n",
       "97    the person who has the highest score wins the ...\n",
       "98    for the most part men and women wear the same ...\n",
       "99    look at the woman whom you are listening to fo...\n",
       "Name: TOKENS, Length: 100, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_df['TOKENS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     guardati i piedi o fai finta di essere affasci...\n",
       "1     sei affascinato dal funzionamento della mente ...\n",
       "2     pensa ai tuoi sentimenti di amore passione e l...\n",
       "3     quasi tutti sono in grado di ricevere amore e ...\n",
       "4     accendi il condizionatore sull aria fredda ma ...\n",
       "                            ...                        \n",
       "95    in un modo o nell altro la verità viene sempre...\n",
       "96    organizza dei viaggi nel fine settimana quando...\n",
       "97    pesa le tue valigie prima del viaggio per evit...\n",
       "98    è molto importante non perdere di vista la pro...\n",
       "99    i conigli hanno un ottimo udito e un ottima vi...\n",
       "Name: TOKENS, Length: 100, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it_df['TOKENS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Word Count: 1314\n",
      "Italian Word Count: 1306\n"
     ]
    }
   ],
   "source": [
    "en_df['WORD_COUNT'] = en_df['TOKENS'].apply(tokenizer.tokenize).apply(lambda token_list: len(token_list))\n",
    "it_df['WORD_COUNT'] = it_df['TOKENS'].apply(tokenizer.tokenize).apply(lambda token_list: len(token_list))\n",
    "\n",
    "en_sum = 0\n",
    "it_sum = 0\n",
    "\n",
    "for count in en_df['WORD_COUNT']:\n",
    "    en_sum += count\n",
    "\n",
    "for count in it_df['WORD_COUNT']:\n",
    "    it_sum += count\n",
    "\n",
    "print('English Word Count: %s\\nItalian Word Count: %d' % (en_sum, it_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Unique Word Count: 0\n",
      "Italian Unique Word Count: 0\n"
     ]
    }
   ],
   "source": [
    "en_unique = []\n",
    "it_unique = []\n",
    "\n",
    "print('English Unique Word Count: %s\\nItalian Unique Word Count: %d' % (len(en_unique), len(it_unique)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
