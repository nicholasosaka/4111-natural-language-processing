{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as matplot\n",
    "import nltk\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = pd.read_csv('data/CONcreTEXT_trial_EN.tsv', sep='\\t') # load data files\n",
    "it_df = pd.read_csv('data/CONcreTEXT_trial_IT.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Dictionary Size: 1314\n",
      "Italian Dictionary Size: 1306\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "en_df['TOKENS'] = en_df['TEXT'].apply(lambda x: x.lower()).apply(tokenizer.tokenize)\n",
    "it_df['TOKENS'] = it_df['TEXT'].apply(lambda x: x.lower()).apply(tokenizer.tokenize)\n",
    "\n",
    "en_words = [word for sentence in en_df['TOKENS'] for word in sentence]\n",
    "it_words = [word for sentence in it_df['TOKENS'] for word in sentence]\n",
    "\n",
    "print('English Dictionary Size: %s\\nItalian Dictionary Size: %d' % (len(en_words), len(it_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train = []\n",
    "en_test = []\n",
    "\n",
    "it_train = []\n",
    "it_test = []\n",
    "\n",
    "state = 4111 # consistent state for testing, used 3951, 4111, 0, 42 for different states.\n",
    "en_train, en_test = sklearn.model_selection.train_test_split(en_words, train_size=0.8, test_size=0.2, random_state=state)\n",
    "it_train, it_test = sklearn.model_selection.train_test_split(it_words, train_size=0.8, test_size=0.2, random_state=state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "*Notes on processing*: All words have been converted to lowercase, and I think that minimizing the \"randomness\" of having some words be capitalized and others be lowercase will help accuracy. I also did not use START and STOP sequences as each letter is being analyzed individually, so START and STOP would have no impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English unigrams\n",
    "en_unigrams = []\n",
    "for word in en_train:\n",
    "    unigram = [character for character in word]\n",
    "    en_unigrams.append(unigram)\n",
    "    \n",
    "# Italian unigrams\n",
    "it_unigrams = []\n",
    "for word in it_train:\n",
    "    unigram = [character for character in word]\n",
    "    it_unigrams.append(unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distribution of letters\n",
    "en_unifreqdist = nltk.FreqDist()\n",
    "for unigram in en_unigrams:\n",
    "    en_unifreqdist += nltk.FreqDist(unigram)\n",
    "    \n",
    "it_unifreqdist = nltk.FreqDist()\n",
    "for unigram in it_unigrams:\n",
    "    it_unifreqdist += nltk.FreqDist(unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_test_df = pd.DataFrame(en_test, columns=['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_probabilities = []\n",
    "it_probabilities = []\n",
    "for index in en_test_df.index:\n",
    "    characters = [characters for characters in en_test_df.loc[index]['Word']]\n",
    "    \n",
    "    en_probability = 1\n",
    "    it_probability = 1\n",
    "    \n",
    "    for character in characters:\n",
    "        en_probability *= en_unifreqdist.freq(character)\n",
    "        it_probability *= it_unifreqdist.freq(character)\n",
    "\n",
    "    en_probabilities.append(en_probability)\n",
    "    it_probabilities.append(it_probability)\n",
    "    \n",
    "en_test_df['English Unigram'] = en_probabilities\n",
    "en_test_df['Italian Unigram'] = it_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.837% over a test size of 263\n"
     ]
    }
   ],
   "source": [
    "unicorrect = 0\n",
    "classification = []\n",
    "for index in en_test_df.index:\n",
    "    if en_test_df.loc[index]['English Unigram'] > en_test_df.loc[index]['Italian Unigram']:\n",
    "        unicorrect += 1\n",
    "        classification.append(\"English\")\n",
    "    else:\n",
    "        classification.append(\"Italian\")\n",
    "\n",
    "en_test_df['Unigram'] = classification\n",
    "print(\"Accuracy: {:.3%} over a test size of {}\".format(unicorrect/len(en_test_df), len(en_test_df)))\n",
    "unigram_accuracy = unicorrect/len(en_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "When constructing bigrams, I chose to use the nltk.bigrams() function as a helper tool. I didn't want to reinvent the wheel. I inserted START and STOP codes at the appropriate places. Additionally, we only construct bigrams for words that are longer than length 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start and stop sequences\n",
    "START = \"START\"\n",
    "STOP = \"STOP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_bigrams = []\n",
    "for word in en_train:\n",
    "    if len(word) > 1:\n",
    "        bg = list(nltk.bigrams(word))\n",
    "        bg.insert(0, (START, bg[0][0]))\n",
    "        bg.append((bg[len(bg)-1][1], STOP))\n",
    "\n",
    "        for bigram in bg:\n",
    "            en_bigrams.append(bigram)\n",
    "\n",
    "            \n",
    "it_bigrams = []\n",
    "for word in it_train:\n",
    "    if len(word) > 1:\n",
    "        bg = list(nltk.bigrams(word))\n",
    "        bg.insert(0, (START, bg[0][0]))\n",
    "        bg.append((bg[len(bg)-1][1], STOP))\n",
    "\n",
    "        for bigram in bg:\n",
    "            it_bigrams.append(bigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distribution of letters\n",
    "en_conditional_freqdist = nltk.ConditionalFreqDist( (preceeding, word) for (preceeding, word) in en_bigrams)\n",
    "it_conditional_freqdist = nltk.ConditionalFreqDist( (preceeding, word) for (preceeding, word) in it_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_probabilities = []\n",
    "it_probabilities = []\n",
    "for index in en_test_df.index:\n",
    "    \n",
    "    en_probability = 0\n",
    "    it_probability = 0\n",
    "    \n",
    "    if len(en_test_df.loc[index]['Word']) > 1:\n",
    "        bigrams = list(nltk.bigrams(en_test_df.loc[index]['Word']))\n",
    "\n",
    "        en_probability = 1\n",
    "        it_probability = 1\n",
    "        \n",
    "        for bigram in bigrams:\n",
    "            (preceeding, word) = bigram\n",
    "            en_probability *= en_conditional_freqdist[preceeding].freq(word)\n",
    "            it_probability *= it_conditional_freqdist[preceeding].freq(word)\n",
    "\n",
    "    else:\n",
    "        en_probability = -1\n",
    "        it_probability = -1\n",
    "    \n",
    "    en_probabilities.append(en_probability)\n",
    "    it_probabilities.append(it_probability)\n",
    "\n",
    "\n",
    "en_test_df['English Bigram'] = en_probabilities\n",
    "en_test_df['Italian Bigram'] = it_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.186% over a test size of 263\n"
     ]
    }
   ],
   "source": [
    "bicorrect = 0\n",
    "classification = []\n",
    "for index in en_test_df.index:\n",
    "    if en_test_df.loc[index]['English Bigram'] > en_test_df.loc[index]['Italian Bigram']:\n",
    "        bicorrect += 1\n",
    "        classification.append(\"English\")\n",
    "    else:\n",
    "        classification.append(\"Italian\")\n",
    "\n",
    "en_test_df['Bigram'] = classification\n",
    "print(\"Accuracy: {:.3%} over a test size of {}\".format(bicorrect/len(en_test_df), len(en_test_df)))\n",
    "bigram_accuracy = bicorrect/len(en_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 Discussion\n",
    "\n",
    "The accuracy for a bigram model was SIGNIFICANTLY higher than a unigram model. Refer to comparison below. For some random states when splitting the train/test groups, we only see a ~5-7% increase in accuracy, but for a random state of 4111 (course code!) we see a whopping ~17% increase.\n",
    "\n",
    "Therefore, we can say that a bigram character-level language model is better at distinguishing langage than a unigram character-level language model. \n",
    "\n",
    "This is pretty clear why. Having more context for the relationship of the letter to it's predecessor means that we can see if a word contains a certain combination that is unlikely to appear in Italian, but very common in English. This can be attributed to the evolution of languages, as over time languages diverge and develop seperately, and the bigram model (and possibly trigram model) allows for us to see some differences.\n",
    "\n",
    "In a unigram model, we're reaching into a scrabble bag and just picking letters. This only lets us look at raw frequency. It is not sufficient to determine language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for unigram model:\t60.837%\n",
      "Accuracy for bigram model:\t77.186%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for unigram model:\\t{:.3%}\\nAccuracy for bigram model:\\t{:.3%}\".format(unigram_accuracy, bigram_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
