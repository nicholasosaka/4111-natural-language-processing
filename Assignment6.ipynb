{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as matplot\n",
    "import nltk\n",
    "import sklearn as sk\n",
    "import re\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>POS</th>\n",
       "      <th>INDEX</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>achievement</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>Bring up academic achievements , awards , and ...</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>achievement</td>\n",
       "      <td>N</td>\n",
       "      <td>9</td>\n",
       "      <td>Please list people you have helped , your pers...</td>\n",
       "      <td>3.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>activate</td>\n",
       "      <td>V</td>\n",
       "      <td>1</td>\n",
       "      <td>Add activated carbon straight to your vodka .</td>\n",
       "      <td>3.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>activate</td>\n",
       "      <td>V</td>\n",
       "      <td>15</td>\n",
       "      <td>Place sensors around your garden , and when a ...</td>\n",
       "      <td>5.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adventure</td>\n",
       "      <td>N</td>\n",
       "      <td>9</td>\n",
       "      <td>Look for a partner that shares your level of a...</td>\n",
       "      <td>2.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TARGET POS  INDEX                                               TEXT  \\\n",
       "0  achievement   N      3  Bring up academic achievements , awards , and ...   \n",
       "1  achievement   N      9  Please list people you have helped , your pers...   \n",
       "2     activate   V      1     Add activated carbon straight to your vodka .    \n",
       "3     activate   V     15  Place sensors around your garden , and when a ...   \n",
       "4    adventure   N      9  Look for a partner that shares your level of a...   \n",
       "\n",
       "   MEAN  \n",
       "0  3.06  \n",
       "1  3.03  \n",
       "2  3.83  \n",
       "3  5.51  \n",
       "4  2.03  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_df_raw = pd.read_csv('data/CONcreTEXT_trial_EN.tsv', sep='\\t') # load data files\n",
    "it_df_raw = pd.read_csv('data/CONcreTEXT_trial_IT.tsv', sep='\\t')\n",
    "\n",
    "en_df = pd.DataFrame()\n",
    "it_df = pd.DataFrame()\n",
    "\n",
    "en_df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df['SENTENCES'] = en_df_raw['TEXT'].apply(lambda sent: sent.strip().lower())\n",
    "it_df['SENTENCES'] = it_df_raw['TEXT'].apply(lambda sent: sent.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r\"[A-Za-zÀ-ÖØ-öø-ÿ']+\") # because I want to keep apostrophes and accented characters\n",
    "en_df['WORDS'] = en_df['SENTENCES'].apply(tokenizer.tokenize)\n",
    "it_df['WORDS'] = it_df['SENTENCES'].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'bring',\n",
       " 'up',\n",
       " 'academic',\n",
       " 'achievements',\n",
       " 'awards',\n",
       " 'and',\n",
       " 'other',\n",
       " 'milestones',\n",
       " 'in',\n",
       " 'your',\n",
       " 'life',\n",
       " '</s>']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_df['TOKENS'] = en_df['WORDS'].apply(lambda words: [\"<s>\"] + words + [\"</s>\"])\n",
    "it_df['TOKENS'] = it_df['WORDS'].apply(lambda words: [\"<s>\"] + words + [\"</s>\"])\n",
    "en_df['TOKENS'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab = nltk.lm.Vocabulary([word for sentence in en_df['WORDS'] for word in sentence])\n",
    "len(en_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPMI:\n",
    "    def __init__(self, sentences, window_size=3):\n",
    "        self.w = window_size\n",
    "        self.sentences = sentences\n",
    "\n",
    "        self.bagofwords = [word for sentence in self.sentences for word in sentence]\n",
    "        self.vocab = nltk.lm.Vocabulary(self.bagofwords)\n",
    "        self.Z = len(self.bagofwords)\n",
    "        self.comatrix = pd.DataFrame(0, columns=self.vocab, index=self.vocab, dtype=np.float32)\n",
    "        self.ppmimx = pd.DataFrame(0, columns=self.vocab, index=self.vocab, dtype=np.float32)\n",
    "        \n",
    "        self.compute()\n",
    "        \n",
    "    def compute(self):\n",
    "        tokens = list(self.vocab) # so we can use the symmetry\n",
    "        \n",
    "        # map co-occurances\n",
    "        index = 0\n",
    "        for word1 in tokens[0:]:\n",
    "            for word2 in tokens[index+1:]:\n",
    "                self.comatrix[word1][word2] += self.co(word1, word2)\n",
    "            index += 1\n",
    "            \n",
    "        for col in self.comatrix.index:\n",
    "            for row in self.comatrix.index:\n",
    "                self.comatrix[row][col] = self.comatrix[col][row]\n",
    "\n",
    "                \n",
    "        #compute ppmi\n",
    "        index = 0\n",
    "        for word1 in tokens[0:]:\n",
    "            for word2 in tokens[index+1:]:\n",
    "                if self.comatrix[word1][word2] > 0:\n",
    "                    numerator = self.comatrix[word1][word2] * self.Z\n",
    "                    denominator = self.vocab[word1] * self.vocab[word2]\n",
    "\n",
    "                    quotient = numerator / denominator\n",
    "                    self.ppmimx[word1][word2] = max(0,np.log(quotient))\n",
    "                \n",
    "            index += 1\n",
    "        \n",
    "        # mirror matrix\n",
    "        for col in self.ppmimx.index:\n",
    "            for row in self.ppmimx.index:\n",
    "                self.ppmimx[row][col] = self.ppmimx[col][row]\n",
    "                \n",
    "    def co(self, word1, word2):\n",
    "        count = 0\n",
    "        for sentence in self.sentences:\n",
    "            for index in range(0, len(sentence)):\n",
    "                if sentence[index] == word1:\n",
    "                    left_slice_index = max(0, index-self.w)\n",
    "                    right_slice_index = index+self.w\n",
    "\n",
    "                    for inner_index, inner_word in enumerate(sentence[left_slice_index : right_slice_index+1]):\n",
    "                        if inner_word == word2: count += 1\n",
    "\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ppmi = PPMI(en_df['TOKENS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>bring</th>\n",
       "      <th>up</th>\n",
       "      <th>academic</th>\n",
       "      <th>achievements</th>\n",
       "      <th>awards</th>\n",
       "      <th>and</th>\n",
       "      <th>other</th>\n",
       "      <th>milestones</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>men</th>\n",
       "      <th>women</th>\n",
       "      <th>wear</th>\n",
       "      <th>same</th>\n",
       "      <th>shoes</th>\n",
       "      <th>woman</th>\n",
       "      <th>whom</th>\n",
       "      <th>she</th>\n",
       "      <th>speaking</th>\n",
       "      <th>&lt;UNK&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.021548</td>\n",
       "      <td>2.021548</td>\n",
       "      <td>2.714695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.817575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bring</th>\n",
       "      <td>2.021548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.933570</td>\n",
       "      <td>6.626718</td>\n",
       "      <td>5.933570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>up</th>\n",
       "      <td>2.021548</td>\n",
       "      <td>5.933570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.626718</td>\n",
       "      <td>5.933570</td>\n",
       "      <td>6.626718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>academic</th>\n",
       "      <td>2.714695</td>\n",
       "      <td>6.626718</td>\n",
       "      <td>6.626718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.626718</td>\n",
       "      <td>7.319865</td>\n",
       "      <td>3.823357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>achievements</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.933570</td>\n",
       "      <td>5.933570</td>\n",
       "      <td>6.626718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.626718</td>\n",
       "      <td>3.130210</td>\n",
       "      <td>5.240423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.319865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whom</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.319865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.319865</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speaking</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.319865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;UNK&gt;</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>646 rows × 646 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   <s>     bring        up  academic  achievements    awards  \\\n",
       "<s>           0.000000  2.021548  2.021548  2.714695      0.000000  0.000000   \n",
       "bring         2.021548  0.000000  5.933570  6.626718      5.933570  0.000000   \n",
       "up            2.021548  5.933570  0.000000  6.626718      5.933570  6.626718   \n",
       "academic      2.714695  6.626718  6.626718  0.000000      6.626718  7.319865   \n",
       "achievements  0.000000  5.933570  5.933570  6.626718      0.000000  6.626718   \n",
       "...                ...       ...       ...       ...           ...       ...   \n",
       "woman         0.000000  0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "whom          0.000000  0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "she           0.000000  0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "speaking      0.000000  0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "<UNK>         0.000000  0.000000  0.000000  0.000000      0.000000  0.000000   \n",
       "\n",
       "                   and     other  milestones        in  ...  men  women  wear  \\\n",
       "<s>           0.000000  0.000000         0.0  0.817575  ...  0.0    0.0   0.0   \n",
       "bring         0.000000  0.000000         0.0  0.000000  ...  0.0    0.0   0.0   \n",
       "up            0.000000  0.000000         0.0  0.000000  ...  0.0    0.0   0.0   \n",
       "academic      3.823357  0.000000         0.0  0.000000  ...  0.0    0.0   0.0   \n",
       "achievements  3.130210  5.240423         0.0  0.000000  ...  0.0    0.0   0.0   \n",
       "...                ...       ...         ...       ...  ...  ...    ...   ...   \n",
       "woman         0.000000  0.000000         0.0  0.000000  ...  0.0    0.0   0.0   \n",
       "whom          0.000000  0.000000         0.0  0.000000  ...  0.0    0.0   0.0   \n",
       "she           0.000000  0.000000         0.0  0.000000  ...  0.0    0.0   0.0   \n",
       "speaking      0.000000  0.000000         0.0  0.000000  ...  0.0    0.0   0.0   \n",
       "<UNK>         0.000000  0.000000         0.0  0.000000  ...  0.0    0.0   0.0   \n",
       "\n",
       "              same  shoes     woman      whom       she  speaking  <UNK>  \n",
       "<s>            0.0    0.0  0.000000  0.000000  0.000000  0.000000    0.0  \n",
       "bring          0.0    0.0  0.000000  0.000000  0.000000  0.000000    0.0  \n",
       "up             0.0    0.0  0.000000  0.000000  0.000000  0.000000    0.0  \n",
       "academic       0.0    0.0  0.000000  0.000000  0.000000  0.000000    0.0  \n",
       "achievements   0.0    0.0  0.000000  0.000000  0.000000  0.000000    0.0  \n",
       "...            ...    ...       ...       ...       ...       ...    ...  \n",
       "woman          0.0    0.0  0.000000  7.319865  0.000000  0.000000    0.0  \n",
       "whom           0.0    0.0  7.319865  0.000000  0.000000  0.000000    0.0  \n",
       "she            0.0    0.0  0.000000  0.000000  0.000000  7.319865    0.0  \n",
       "speaking       0.0    0.0  0.000000  0.000000  7.319865  0.000000    0.0  \n",
       "<UNK>          0.0    0.0  0.000000  0.000000  0.000000  0.000000    0.0  \n",
       "\n",
       "[646 rows x 646 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_ppmi.ppmimx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm I made for forming the PPMI matrix is pretty simple, but I had to optimize some parts to halve the processing time.\n",
    "\n",
    "First, we tokenize the input sentences. I didn't do this as part of my PPMI class since I don't think it should be encapulated by that class, logically speaking.\n",
    "\n",
    "Once we have fed the input tokenized sentences into the class constructor, we construct an NLTK Vocabulary object, as well as a Pandas DataFrame filled with 0s.\n",
    "\n",
    "Then, once compute() is called, we listify the vocabulary so we can use slicing. We slice the two dimensions such that we only compute `[x][y]` instead of both `[x][y]` *and* `[y][x]`. Then, for every combination of two words (excluding symmetrical combinations) we use the sliding window algorithm on each sentence. This ensures that we find all co-occurances for two unique word combinations in each sentence.\n",
    "\n",
    "The sliding window algorithm is pretty simple:\n",
    "For each sentence in our corpus, and for each instance of the search word in a given sentence, we go through the neighboring `K` words to see if the second word is found. We avoid overlooking duplicate words in a sentence ince we don't use the index() function.\n",
    "\n",
    "After we've found all co-occurances and put them in our matrix, we just loop through the same cells as before (the symmetrical subset such that it's from one corner to the diagonal) and compute the probability of the two words independently and use the formula: `log2(cooccurances/probability of individual)`. Then, we just mirror the matrix to the other side of the diagonal.\n",
    "\n",
    "I think the time complexity is around O(n^4) since even though we split the input token size in half computationally, that's a linear growth which doesn't affect the time complexity increase. It's four nested loops with some if conditionals but I think it works out to n^4. It's not great, but it works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "I would look at the maximum ppmi correspondence for a given word `w` and use the `pd.Series.argmax()` function to find the index of the row that has the highest correlation. Now, our corpus only has 100 sentences and ~670 unique words. I expect this to be a pretty sparse matrix due to this fact. But let's look at two examples! We can see below that 'awards' and the words 'achievements', 'milestones' are pretty correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPMI awards, milestones: 7.3198647\n",
      "PPMI awards, achievements: 6.6267176\n",
      "\n",
      "PPMI awards, and: 3.8233573\n"
     ]
    }
   ],
   "source": [
    "print(\"PPMI awards, milestones:\", en_ppmi.ppmimx['awards']['milestones'])\n",
    "print(\"PPMI awards, achievements:\", en_ppmi.ppmimx['awards']['achievements'])\n",
    "\n",
    "print(\"\\nPPMI awards, and:\", en_ppmi.ppmimx['awards']['and'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrast this to 'awards' and 'and'. There's not so much correlation in the corpus there. Now, this doesn't _necessitate_ that 'awards' and 'milestones' are highly correlated in the real world, as our corpus only has 100 sentences, which is not a lot. If we use a corpus of the size of the Google Books library from even just the past year, I think we could find meaningful connections.\n",
    "\n",
    "We would find these relationships by using some sort of unsupervised learning model that clusters word pairings together. I think k-nearest neighbor would do well, since it would easily define clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>guardati</th>\n",
       "      <th>i</th>\n",
       "      <th>piedi</th>\n",
       "      <th>o</th>\n",
       "      <th>fai</th>\n",
       "      <th>finta</th>\n",
       "      <th>di</th>\n",
       "      <th>essere</th>\n",
       "      <th>affascinata</th>\n",
       "      <th>...</th>\n",
       "      <th>conigli</th>\n",
       "      <th>hanno</th>\n",
       "      <th>ottimo</th>\n",
       "      <th>udito</th>\n",
       "      <th>un'</th>\n",
       "      <th>ottima</th>\n",
       "      <th>individuare</th>\n",
       "      <th>predatori</th>\n",
       "      <th>facilmente</th>\n",
       "      <th>&lt;UNK&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.710048</td>\n",
       "      <td>1.668594</td>\n",
       "      <td>2.710048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.724133</td>\n",
       "      <td>0.918289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.710048</td>\n",
       "      <td>2.710048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardati</th>\n",
       "      <td>2.710048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.482005</td>\n",
       "      <td>7.315218</td>\n",
       "      <td>4.917323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1.668594</td>\n",
       "      <td>4.482005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.482005</td>\n",
       "      <td>2.084110</td>\n",
       "      <td>4.482005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.482005</td>\n",
       "      <td>4.482005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.482005</td>\n",
       "      <td>4.482005</td>\n",
       "      <td>4.482005</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piedi</th>\n",
       "      <td>2.710048</td>\n",
       "      <td>7.315218</td>\n",
       "      <td>4.482005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.917323</td>\n",
       "      <td>7.315218</td>\n",
       "      <td>7.315218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.917323</td>\n",
       "      <td>2.084110</td>\n",
       "      <td>4.917323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.917323</td>\n",
       "      <td>4.917323</td>\n",
       "      <td>0.985497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ottima</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.315218</td>\n",
       "      <td>7.315218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>individuare</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.482005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.315218</td>\n",
       "      <td>7.315218</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predatori</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.482005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.315218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.315218</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facilmente</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.482005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.315218</td>\n",
       "      <td>7.315218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;UNK&gt;</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714 rows × 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  <s>  guardati         i     piedi         o       fai  \\\n",
       "<s>          0.000000  2.710048  1.668594  2.710048  0.000000  0.000000   \n",
       "guardati     2.710048  0.000000  4.482005  7.315218  4.917323  0.000000   \n",
       "i            1.668594  4.482005  0.000000  4.482005  2.084110  4.482005   \n",
       "piedi        2.710048  7.315218  4.482005  0.000000  4.917323  7.315218   \n",
       "o            0.000000  4.917323  2.084110  4.917323  0.000000  4.917323   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "ottima       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "individuare  0.000000  0.000000  4.482005  0.000000  0.000000  0.000000   \n",
       "predatori    0.000000  0.000000  4.482005  0.000000  0.000000  0.000000   \n",
       "facilmente   0.000000  0.000000  4.482005  0.000000  0.000000  0.000000   \n",
       "<UNK>        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                finta        di    essere  affascinata  ...   conigli  \\\n",
       "<s>          0.000000  0.724133  0.918289          0.0  ...  2.710048   \n",
       "guardati     0.000000  0.000000  0.000000          0.0  ...  0.000000   \n",
       "i            0.000000  0.000000  0.000000          0.0  ...  4.482005   \n",
       "piedi        7.315218  0.000000  0.000000          0.0  ...  0.000000   \n",
       "o            4.917323  0.985497  0.000000          0.0  ...  0.000000   \n",
       "...               ...       ...       ...          ...  ...       ...   \n",
       "ottima       0.000000  0.000000  0.000000          0.0  ...  0.000000   \n",
       "individuare  0.000000  0.000000  0.000000          0.0  ...  0.000000   \n",
       "predatori    0.000000  0.000000  0.000000          0.0  ...  0.000000   \n",
       "facilmente   0.000000  0.000000  0.000000          0.0  ...  0.000000   \n",
       "<UNK>        0.000000  0.000000  0.000000          0.0  ...  0.000000   \n",
       "\n",
       "                hanno  ottimo     udito       un'  ottima  individuare  \\\n",
       "<s>          2.710048     0.0  0.000000  0.000000     0.0     0.000000   \n",
       "guardati     0.000000     0.0  0.000000  0.000000     0.0     0.000000   \n",
       "i            4.482005     0.0  0.000000  0.000000     0.0     4.482005   \n",
       "piedi        0.000000     0.0  0.000000  0.000000     0.0     0.000000   \n",
       "o            0.000000     0.0  0.000000  0.000000     0.0     0.000000   \n",
       "...               ...     ...       ...       ...     ...          ...   \n",
       "ottima       0.000000     0.0  7.315218  7.315218     0.0     0.000000   \n",
       "individuare  0.000000     0.0  0.000000  0.000000     0.0     0.000000   \n",
       "predatori    0.000000     0.0  0.000000  0.000000     0.0     7.315218   \n",
       "facilmente   0.000000     0.0  0.000000  0.000000     0.0     7.315218   \n",
       "<UNK>        0.000000     0.0  0.000000  0.000000     0.0     0.000000   \n",
       "\n",
       "             predatori  facilmente  <UNK>  \n",
       "<s>           0.000000    0.000000    0.0  \n",
       "guardati      0.000000    0.000000    0.0  \n",
       "i             4.482005    4.482005    0.0  \n",
       "piedi         0.000000    0.000000    0.0  \n",
       "o             0.000000    0.000000    0.0  \n",
       "...                ...         ...    ...  \n",
       "ottima        0.000000    0.000000    0.0  \n",
       "individuare   7.315218    7.315218    0.0  \n",
       "predatori     0.000000    7.315218    0.0  \n",
       "facilmente    7.315218    0.000000    0.0  \n",
       "<UNK>         0.000000    0.000000    0.0  \n",
       "\n",
       "[714 rows x 714 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it_ppmi = PPMI(it_df['TOKENS'])\n",
    "it_ppmi.ppmimx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
