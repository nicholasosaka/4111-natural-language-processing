{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as matplot\n",
    "import nltk\n",
    "import sklearn\n",
    "from random import random, randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Tokens\n",
    "START = \"<\"\n",
    "STOP = \">\"\n",
    "SPACE = \" \"\n",
    "PUNCTUATION = \",\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df_raw = pd.read_csv('data/CONcreTEXT_trial_EN.tsv', sep='\\t') # load data files\n",
    "it_df_raw = pd.read_csv('data/CONcreTEXT_trial_IT.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = pd.DataFrame()\n",
    "it_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SENTENCES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bring up academic achievements , awards , and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>please list people you have helped , your pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>add activated carbon straight to your vodka .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>place sensors around your garden , and when a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>look for a partner that shares your level of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>rinse your face with warm water and pat it dry .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>staying mentally strong means winning half the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>the person who has the highest score wins the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>for the most part , men and women wear the sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>look at the woman whom you are listening to fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            SENTENCES\n",
       "0   bring up academic achievements , awards , and ...\n",
       "1   please list people you have helped , your pers...\n",
       "2       add activated carbon straight to your vodka .\n",
       "3   place sensors around your garden , and when a ...\n",
       "4   look for a partner that shares your level of a...\n",
       "..                                                ...\n",
       "95   rinse your face with warm water and pat it dry .\n",
       "96  staying mentally strong means winning half the...\n",
       "97  the person who has the highest score wins the ...\n",
       "98  for the most part , men and women wear the sam...\n",
       "99  look at the woman whom you are listening to fo...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "en_df['SENTENCES'] = en_df_raw['TEXT'].apply(lambda sent: sent.strip().lower())\n",
    "it_df['SENTENCES'] = it_df_raw['TEXT'].apply(lambda sent: sent.strip().lower())\n",
    "en_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bring up academic achievements , awards , and other milestones in your life .'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_train = []\n",
    "en_test = []\n",
    "\n",
    "it_train = []\n",
    "it_test = []\n",
    "\n",
    "state = 4111\n",
    "en_train, en_test = sklearn.model_selection.train_test_split(en_df['SENTENCES'], train_size=0.8, test_size=0.2, random_state=state)\n",
    "it_train, it_test = sklearn.model_selection.train_test_split(it_df['SENTENCES'], train_size=0.8, test_size=0.2, random_state=state)\n",
    "en_train[0] # show first element of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace (Add-1)\n",
    "\n",
    "I tried using the `nltk.lm.Laplace` model but I couldn't find a way to construct the model using only bigrams, as when i filtered out the unigrams from the everygrams used from the pipeline, it caused a ValueError. So I decided to make my own implementation based on the slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<the fertilizer will inspire leafy growth rather than flower growth .>'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train = [START + sent + STOP for sent in en_train]\n",
    "padded_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<', 't'), ('t', 'h'), ('h', 'e'), ('e', ' '), (' ', 'f')]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = [gram for sent in padded_train for gram in list(nltk.bigrams(sent))]\n",
    "bigrams[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_tokens = nltk.lm.Vocabulary([char for sent in padded_train for char in sent])\n",
    "len(vocab_tokens.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<', 't', 'h', 'e', ' ']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditionals = nltk.ConditionalFreqDist( (pre, suc) for (pre, suc) in bigrams )\n",
    "conditionals.conditions()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Laplace:\n",
    "    def __init__(self, frequency_distribution, vocabulary, seed=None):\n",
    "        self.freqdist = frequency_distribution\n",
    "        self.vocab = vocabulary\n",
    "        self.seed = seed\n",
    "        \n",
    "    def smooth(self, pre, suc):\n",
    "        \"\"\"\n",
    "            P_add-1(w_i | w_i-1) = c(w_i-1, w_i)+1 / c(w_i-1) + V\n",
    "            V is the vocabulary size\n",
    "            \n",
    "        \"\"\"\n",
    "        numerator = self.freqdist[pre][suc] + 1\n",
    "        V = len(self.vocab.counts)\n",
    "        denominator = self.freqdist[pre].N() + V\n",
    "        return numerator/denominator\n",
    "    \n",
    "    def letter(self):\n",
    "        if self.seed == None:\n",
    "            raise ValueError(\"nuh uh uh pls set seed first\")\n",
    "        distribution = self.freqdist[self.seed]\n",
    "        x = random()\n",
    "        for letter in self.freqdist[self.seed]:\n",
    "            x = x - self.smooth(self.seed, letter)\n",
    "            if x <= 0:\n",
    "                self.seed = letter\n",
    "                return letter\n",
    "    \n",
    "    def generate_sentence(self, max_len=100, start=\"<\"):\n",
    "        self.seed = start\n",
    "        sentence = \"\"\n",
    "        \n",
    "        size = 0\n",
    "        while \">\" not in sentence and size <= max_len:\n",
    "            letter = self.letter()\n",
    "            if letter == None:\n",
    "                letter = \"\"\n",
    "            sentence += letter\n",
    "            size += 1\n",
    "        return sentence[:-1] #trim off the stop token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 35\tis ce pl llkigbe we t sis tasng t .\n",
      "Length: 13\tchoifiluted .\n",
      "Length: 7\tcacan .\n",
      "Length: 91\tyokittt yentofleacangorigh t ans epredesstureffouthovesoufe parvizemurokeshens micke sta r \n",
      "Length: 93\te ark tafeme ierse angoroug ce thererecandotwil t barcato , ly erwhesiowtearithi tiveriuraver\n"
     ]
    }
   ],
   "source": [
    "en_laplace = Laplace(conditionals, vocab_tokens) #\n",
    "for _ in range(5):\n",
    "    s = en_laplace.generate_sentence()\n",
    "    print(\"Length: \" + str(len(s)) + \"\\t\" + s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It works!** :O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999997 and it's basically 1\n"
     ]
    }
   ],
   "source": [
    "# proof that it actually smooths over all vocabulary counts, not just ones that exist as a bigram pair\n",
    "prob = 0\n",
    "for i in en_laplace.vocab.counts: # all the tokens\n",
    "    prob += en_laplace.smooth(\"<\",i)\n",
    "print(str(prob) + \" and it's basically 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Interpolation\n",
    "(Equally weighted lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_generator, vocab_generator = nltk.lm.preprocessing.padded_everygram_pipeline(2, en_train)\n",
    "\n",
    "# listify because i hate generators\n",
    "ngrams = [list(generator) for generator in list(ngrams_generator)]\n",
    "vocabulary = list(vocab_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "kneserney = nltk.lm.KneserNeyInterpolated(2)\n",
    "kneserney.fit(ngrams, vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lots easier than Add-1, since linear interpolation uses everygrams less than or equal to the max length**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 64\t ierelf y izactisilf yo bes mismill wtint tyoes yocha s the fo .\n",
      "Length: 47\tisstste pareler res souterbed ord w lon dotak .\n",
      "Length: 13\tuplfoowicon .\n",
      "Length: 90\te iprs h veway onten f when y edravor wou or s , tssony te tsadklve iminspan welinyoad ort\n",
      "Length: 49\tallstoth , plor pate ll oteny ipr bultthawike t .\n"
     ]
    }
   ],
   "source": [
    "# laplace sentence creation\n",
    "possible_starts=['a','r','u','m','p','q','h']\n",
    "\n",
    "\n",
    "en_laplace = Laplace(conditionals, vocab_tokens)\n",
    "for _ in range(5):\n",
    "    s = en_laplace.generate_sentence(100, possible_starts[randrange(len(possible_starts))])\n",
    "    print(\"Length: \" + str(len(s)) + \"\\t\" + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 98\t t wanourely foule a .you . wheg thadserith fing o co toopioul qufoude thaphourterine in cen cl rv\n",
      "Length: 98\t tan ateal vizamomus â€™r f maicer a .zalestspalll y bo at .0 y rs s h bl yown itidvilarsurs , me ti\n",
      "Length: 96\tin by plalad 'llou e .g y an hapas tsmoaponyoiresowaf te the t w r rnd .d breshat ., h .ifoingem\n",
      "Length: 98\telse y ctomperrs mavelitisplden whooil .wisid .qu ftty d an ant usoufoppastene somifsovo intave ch\n",
      "Length: 99\tngizeth e ftply the watulouin , thimima dy ory tiresof wins 'le yof an .â€™l , akitithodindesharsocan\n"
     ]
    }
   ],
   "source": [
    "# kneser ney letter and sentence generation\n",
    "possible_starts=['a','r','u','m','p','q','h']\n",
    "\n",
    "possible_starts[randrange(len(possible_starts))]\n",
    "\n",
    "for _ in range(5):\n",
    "    source = kneserney.generate(100, text_seed=possible_starts[randrange(len(possible_starts))])\n",
    "    s = \"\".join([token for token in source if token != '</s>' and token != '<s>'])\n",
    "    print(\"Length: \" + str(len(s)) + \"\\t\" + s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_generator, vocab_generator = nltk.lm.preprocessing.padded_everygram_pipeline(2, en_train)\n",
    "\n",
    "# listify because i hate generators\n",
    "ngrams = [list(generator) for generator in list(ngrams_generator)]\n",
    "vocabulary = list(vocab_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "kneserney = nltk.lm.KneserNeyInterpolated(3)\n",
    "kneserney.fit(ngrams, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 99\tuse meffor win he , rowithal at as .jorilene in s , cr al haddel inddrt ieavin mang bitlltimatonsil\n",
      "Length: 99\ter .g w g pre yomplyoter mavou crideaveris choges f fll bimoldeerier , wir arins tedircoveesoce ss \n",
      "Length: 99\tare areadephe tegalilpy sthe toom , y ghennstopalllouteng cank igan fe .s f as or ouss iest wsinshe\n",
      "Length: 98\texplyecerored s o s shene , s ncals iof yom bll .plusestamicouthe re y the g uputhr .tenco wisp da\n",
      "Length: 99\tofe t ct te a t greanutou qurear cansanemat s the pader al .it e acar chisshesaste ju y y ooutlyour\n"
     ]
    }
   ],
   "source": [
    "possible_starts=['a','r','u','m','p','q','h']\n",
    "\n",
    "possible_starts[randrange(len(possible_starts))]\n",
    "\n",
    "for _ in range(5):\n",
    "    source = kneserney.generate(100, text_seed=possible_starts[randrange(len(possible_starts))])\n",
    "    s = \"\".join([token for token in source if token != '</s>' and token != '<s>'])\n",
    "    print(\"Length: \" + str(len(s)) + \"\\t\" + s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
