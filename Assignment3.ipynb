{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as matplot\n",
    "import nltk\n",
    "import sklearn\n",
    "from random import random, randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Tokens\n",
    "START = \"<\"\n",
    "STOP = \">\"\n",
    "SPACE = \" \"\n",
    "PUNCTUATION = \",\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df_raw = pd.read_csv('data/CONcreTEXT_trial_EN.tsv', sep='\\t') # load data files\n",
    "it_df_raw = pd.read_csv('data/CONcreTEXT_trial_IT.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = pd.DataFrame()\n",
    "it_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SENTENCES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bring up academic achievements , awards , and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>please list people you have helped , your pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>add activated carbon straight to your vodka .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>place sensors around your garden , and when a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>look for a partner that shares your level of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>rinse your face with warm water and pat it dry .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>staying mentally strong means winning half the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>the person who has the highest score wins the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>for the most part , men and women wear the sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>look at the woman whom you are listening to fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            SENTENCES\n",
       "0   bring up academic achievements , awards , and ...\n",
       "1   please list people you have helped , your pers...\n",
       "2       add activated carbon straight to your vodka .\n",
       "3   place sensors around your garden , and when a ...\n",
       "4   look for a partner that shares your level of a...\n",
       "..                                                ...\n",
       "95   rinse your face with warm water and pat it dry .\n",
       "96  staying mentally strong means winning half the...\n",
       "97  the person who has the highest score wins the ...\n",
       "98  for the most part , men and women wear the sam...\n",
       "99  look at the woman whom you are listening to fo...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "en_df['SENTENCES'] = en_df_raw['TEXT'].apply(lambda sent: sent.strip().lower())\n",
    "it_df['SENTENCES'] = it_df_raw['TEXT'].apply(lambda sent: sent.strip().lower())\n",
    "en_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bring up academic achievements , awards , and other milestones in your life .'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_train = []\n",
    "en_test = []\n",
    "\n",
    "it_train = []\n",
    "it_test = []\n",
    "\n",
    "state = 4111\n",
    "en_train, en_test = sklearn.model_selection.train_test_split(en_df['SENTENCES'], train_size=0.8, test_size=0.2, random_state=state)\n",
    "it_train, it_test = sklearn.model_selection.train_test_split(it_df['SENTENCES'], train_size=0.8, test_size=0.2, random_state=state)\n",
    "en_train[0] # show first element of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace (Add-1)\n",
    "\n",
    "I tried using the `nltk.lm.Laplace` model but I couldn't find a way to construct the model using only bigrams, as when i filtered out the unigrams from the everygrams used from the pipeline, it caused a ValueError. So I decided to make my own implementation based on the slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<the fertilizer will inspire leafy growth rather than flower growth .>'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train = [START + sent + STOP for sent in en_train]\n",
    "padded_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<', 't'), ('t', 'h'), ('h', 'e'), ('e', ' '), (' ', 'f')]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = [gram for sent in padded_train for gram in list(nltk.bigrams(sent))]\n",
    "bigrams[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_tokens = nltk.lm.Vocabulary([char for sent in padded_train for char in sent])\n",
    "len(vocab_tokens.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<', 't', 'h', 'e', ' ']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditionals = nltk.ConditionalFreqDist( (pre, suc) for (pre, suc) in bigrams )\n",
    "conditionals.conditions()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Laplace:\n",
    "    def __init__(self, frequency_distribution, vocabulary, seed=None):\n",
    "        self.freqdist = frequency_distribution\n",
    "        self.vocab = vocabulary\n",
    "        self.seed = seed\n",
    "        \n",
    "    def smooth(self, pre, suc):\n",
    "        \"\"\"\n",
    "            P_add-1(w_i | w_i-1) = c(w_i-1, w_i)+1 / c(w_i-1) + V\n",
    "            V is the vocabulary size\n",
    "            \n",
    "        \"\"\"\n",
    "        numerator = self.freqdist[pre][suc] + 1\n",
    "        V = len(self.vocab.counts)\n",
    "        denominator = self.freqdist[pre].N() + V\n",
    "        return numerator/denominator\n",
    "    \n",
    "    def letter(self):\n",
    "        if self.seed == None:\n",
    "            raise ValueError(\"nuh uh uh pls set seed first\")\n",
    "        distribution = self.freqdist[self.seed]\n",
    "        x = random()\n",
    "        for letter in self.freqdist[self.seed]:\n",
    "            x = x - self.smooth(self.seed, letter)\n",
    "            if x <= 0:\n",
    "                self.seed = letter\n",
    "                return letter\n",
    "    \n",
    "    def generate_sentence(self, max_len=100, start=\"<\"):\n",
    "        self.seed = start\n",
    "        sentence = \"\"\n",
    "        \n",
    "        size = 0\n",
    "        while \">\" not in sentence and size <= max_len:\n",
    "            letter = self.letter()\n",
    "            if letter == None:\n",
    "                letter = \"\"\n",
    "            sentence += letter\n",
    "            size += 1\n",
    "        return sentence[:-1] #trim off the stop token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 28\tmiourtodletmeriene ie alke .\n",
      "Length: 34\tdes pons you wthas ath techeanes .\n",
      "Length: 92\ttecl malisteplling f othotttonsmatr chers a ayonghyscksit tok cusunyounspardeeoof ads a tudi\n",
      "Length: 92\tomathereveskin laveve , se asin sin pis atreve a toyon oficemperes e ckicrt lyin inort tay t\n",
      "Length: 16\tiola patescexp .\n"
     ]
    }
   ],
   "source": [
    "en_laplace = Laplace(conditionals, vocab_tokens) #\n",
    "for _ in range(5):\n",
    "    s = en_laplace.generate_sentence()\n",
    "    print(\"Length: \" + str(len(s)) + \"\\t\" + s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It works!** :O thanks erfan for all the help with my questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999997 and it's basically 1\n"
     ]
    }
   ],
   "source": [
    "# proof that it actually smooths over all vocabulary counts, not just ones that exist as a bigram pair\n",
    "prob = 0\n",
    "for i in en_laplace.vocab.counts: # all the tokens\n",
    "    prob += en_laplace.smooth(\"<\",i)\n",
    "print(str(prob) + \" and it's basically 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Interpolation\n",
    "(Equally weighted lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_generator, vocab_generator = nltk.lm.preprocessing.padded_everygram_pipeline(2, en_train)\n",
    "\n",
    "# listify because i hate generators\n",
    "ngrams = [list(generator) for generator in list(ngrams_generator)]\n",
    "vocabulary = list(vocab_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "kneserney = nltk.lm.KneserNeyInterpolated(2)\n",
    "kneserney.fit(ngrams, vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lots easier than Add-1, since linear interpolation uses everygrams less than or equal to the max length**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 96\torthinyor wicacanghace cothe intern 't yommunes ant fattrous ddelyo cacunuf matur oourinistho ar\n",
      "Length: 81\tulyor wher canss metcoun oth dd bowhr wedkenu brnt jotusn yo wh rspan itllthan f \n",
      "Length: 7\t teak .\n",
      "Length: 69\td isse lis henghoang coreny wite ancontrevesneyoudexif l ofith grin .\n",
      "Length: 22\tthexiresott ar en or .\n"
     ]
    }
   ],
   "source": [
    "# laplace sentence creation\n",
    "possible_starts=['a','r','u','m','p','q','h']\n",
    "\n",
    "\n",
    "en_laplace = Laplace(conditionals, vocab_tokens)\n",
    "for _ in range(5):\n",
    "    s = en_laplace.generate_sentence(100, possible_starts[randrange(len(possible_starts))])\n",
    "    print(\"Length: \" + str(len(s)) + \"\\t\" + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 99\t chale veingameratowanysongin chits nn .hel tedomers s mit ber he bee pathinsoourouennod sece wil h\n",
      "Length: 97\tesusit fed y prs mind ly e , , matherg torutoowin caves hokes tir , smurt puly ...onghive foute s\n",
      "Length: 100\t upak ntomenore g tisaspa trowad ome s pl donyofl whasubedy winesilene aveneryol jourowhateaircomepy\n",
      "Length: 99\tees arissen pasou d ong conye ho 'splonndran thoint ar omews ther y silyier moutrtak y ste .emoug m\n",
      "Length: 99\tiddil pa an are proucell an caveathandsus p , an cakintlinghamean .tin cooro pamesot dr f baursthec\n"
     ]
    }
   ],
   "source": [
    "# kneser ney letter and sentence generation\n",
    "possible_starts=['a','r','u','m','p','q','h']\n",
    "\n",
    "possible_starts[randrange(len(possible_starts))]\n",
    "\n",
    "for _ in range(5):\n",
    "    source = kneserney.generate(100, text_seed=possible_starts[randrange(len(possible_starts))])\n",
    "    s = \"\".join([token for token in source if token != '</s>' and token != '<s>'])\n",
    "    print(\"Length: \" + str(len(s)) + \"\\t\" + s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_generator, vocab_generator = nltk.lm.preprocessing.padded_everygram_pipeline(3, en_train)\n",
    "\n",
    "# listify because i hate generators\n",
    "ngrams = [list(generator) for generator in list(ngrams_generator)]\n",
    "vocabulary = list(vocab_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kneserney = nltk.lm.KneserNeyInterpolated(3)\n",
    "kneserney.fit(ngrams, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 37\t th a othe miessimposs ing unt inve .\n",
      "Length: 100\tdiour oven ponturserges spy ant parovence can phe ore our a must , ance foreall , ant by thent it ac\n",
      "Length: 19\tr the arepess whe .\n",
      "Length: 21\tt care an st sou 's .\n",
      "Length: 100\trou 've evelace : re afeal for ing to ma ned ove ter of wist exis in artal , bods owitchin dooke a l\n"
     ]
    }
   ],
   "source": [
    "possible_starts=['a','r','u','m','p','q','h']\n",
    "\n",
    "possible_starts[randrange(len(possible_starts))]\n",
    "\n",
    "for _ in range(5):\n",
    "    source = kneserney.generate(100, text_seed=possible_starts[randrange(len(possible_starts))])\n",
    "    s = \"\".join([token for token in source if token != '</s>' and token != '<s>'])\n",
    "    print(\"Length: \" + str(len(s)) + \"\\t\" + s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_generator, vocab_generator = nltk.lm.preprocessing.padded_everygram_pipeline(2, it_train)\n",
    "\n",
    "# listify because i hate generators againnn\n",
    "ngrams = [list(generator) for generator in list(ngrams_generator)]\n",
    "vocabulary = list(vocab_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_bikneserney = nltk.lm.KneserNeyInterpolated(2)\n",
    "it_bikneserney.fit(ngrams, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC ITALIAN BIGRAM SENTENCES:\n",
      "Length: 99\tunnorcorta e i io .g pa due gi val e del' ca iu pl' uÃ² diotile , azzi meme utolistusunariaden sssan\n",
      "Length: 99\tma nacin eg , arl ffen tta ce Ã¨ domen derelivi glle de , 125 ata dimantrmidi sttomia ate o .ka roio\n",
      "Length: 99\ttistataronsi erce ssomea tttreze stiba onttÃ  ri cisagai desunnalersco udifi mobio .morbendolitti ch\n",
      "Length: 96\tmustei io ari.25 to stricimene coza din nn .' dâ€™ di latolampaseli de le muttra tai le .pe sticor\n",
      "Length: 99\t pil ia mativemeltrantinsi cobarinisorcinffforti comaltevica cana ca iegle pri trma l .hi pee uontÃ \n"
     ]
    }
   ],
   "source": [
    "# kneser ney letter and sentence generation\n",
    "possible_starts=['a','r','u','m','p','q','h']\n",
    "\n",
    "possible_starts[randrange(len(possible_starts))]\n",
    "print(\"EC ITALIAN BIGRAM SENTENCES:\")\n",
    "for _ in range(5):\n",
    "    source = it_bikneserney.generate(100, text_seed=possible_starts[randrange(len(possible_starts))])\n",
    "    s = \"\".join([token for token in source if token != '</s>' and token != '<s>'])\n",
    "    print(\"Length: \" + str(len(s)) + \"\\t\" + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_generator, vocab_generator = nltk.lm.preprocessing.padded_everygram_pipeline(3, it_train)\n",
    "\n",
    "# listify because i hate generators\n",
    "ngrams = [list(generator) for generator in list(ngrams_generator)]\n",
    "vocabulary = list(vocab_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_trikneserney = nltk.lm.KneserNeyInterpolated(3)\n",
    "it_trikneserney.fit(ngrams, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC ITALIAN TRIGRAM SENTENCES:\n",
      "Length: 100\tertempettÃ  e sta strovamperitorgendelle colpazi aveccola persiclupere ci rissu i , perchichima dellu\n",
      "Length: 17\tdee lorza della .\n",
      "Length: 100\tasimaspiÃ¹ peririclesso sque orta chÃ© suppa masamin sto , sti soppa vuo esatane lavo con unquiniattic\n",
      "Length: 57\tri Ã¨ comun unquellaveri hai percata piÃ¹ puÃ² e sitÃ  a lo .\n",
      "Length: 35\tua pio la un tire di so la , l' e .\n"
     ]
    }
   ],
   "source": [
    "# kneser ney letter and sentence generation\n",
    "possible_starts=['a','r','u','m','p','q','h']\n",
    "\n",
    "possible_starts[randrange(len(possible_starts))]\n",
    "print(\"EC ITALIAN TRIGRAM SENTENCES:\")\n",
    "for _ in range(5):\n",
    "    source = it_trikneserney.generate(100, text_seed=possible_starts[randrange(len(possible_starts))])\n",
    "    s = \"\".join([token for token in source if token != '</s>' and token != '<s>'])\n",
    "    print(\"Length: \" + str(len(s)) + \"\\t\" + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_generator, vocab_generator = nltk.lm.preprocessing.padded_everygram_pipeline(6, en_train)\n",
    "\n",
    "# listify because i hate generators\n",
    "ngrams = [list(generator) for generator in list(ngrams_generator)]\n",
    "vocabulary = list(vocab_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn = nltk.lm.KneserNeyInterpolated(6)\n",
    "kn.fit(ngrams, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"n the hole in you 've imagined any other are relaxing ways to not insult or offend anyone .\""
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kneser ney letter and sentence generation\n",
    "source = kn.generate(200)\n",
    "s = \"\".join([token for token in source if token != '</s>' and token != '<s>'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
